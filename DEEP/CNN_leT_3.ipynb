{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:21:23.122791Z",
     "start_time": "2024-05-28T10:21:22.808327Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions utilitaires pour parcourir les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:21:23.129519Z",
     "start_time": "2024-05-28T10:21:23.123955Z"
    }
   },
   "outputs": [],
   "source": [
    "common_path = \"../chest_Xray/\"\n",
    "images_files = os.listdir(common_path)\n",
    "subfolders = [\"train\",\"val\",\"test\"]\n",
    "categories = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "\n",
    "# Permet de parcourir les images, et pour chaque image, on applique une fonction de callback\n",
    "# On peut optionnellement appeler une fonction de callback pour chaque dossier\n",
    "def browse_imgs(img_callback, path_folder_callback = None, limit_size = None):\n",
    "    for subfolder in subfolders:\n",
    "        for category in categories:\n",
    "            # pour avoir tous les chemins des 6 dossiers\n",
    "            folder_path = os.path.join(common_path, subfolder, category)\n",
    "            # liste de toutes les images\n",
    "            images_files = os.listdir(folder_path)\n",
    "            if path_folder_callback is not None:\n",
    "                path_folder_callback(folder_path, images_files)\n",
    "            array_limit = limit_size if limit_size is not None else len(images_files)\n",
    "            #récupération de toutes les (ou des 'limit_size' premières) images du dossier.\n",
    "            for file_name in images_files[:array_limit]:\n",
    "                if not file_name.endswith(\".jpeg\"):\n",
    "                    continue\n",
    "                image_path = os.path.join(folder_path,file_name)\n",
    "                img = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "                img_callback(img, category)\n",
    "                \n",
    "                \n",
    "def display_imgs(imgs, titles = [], plot_size = (1,1), figsize = (10,8)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    index = 0\n",
    "    for image, title in zip(imgs, titles):\n",
    "        index += 1\n",
    "        ax = fig.add_subplot(plot_size[0], plot_size[1], index) \n",
    "        ax.imshow(image, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        if titles is not None:\n",
    "            ax.set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:21:23.132639Z",
     "start_time": "2024-05-28T10:21:23.130402Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def img_is_in_ratio(img, min_ratio = 1, max_ratio = 1.5):\n",
    "    height, width = img.shape\n",
    "    ratio = width / height\n",
    "    if min_ratio <= ratio <= max_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:21:23.135806Z",
     "start_time": "2024-05-28T10:21:23.133528Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grey_scale_limit = 10\n",
    "\n",
    "def img_has_atleast_black_pixels(img, threshold = 5):\n",
    "    height, width = img.shape\n",
    "    percent = (np.sum(img <= grey_scale_limit)*100)/(width*height)\n",
    "    return percent >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:22:02.593104Z",
     "start_time": "2024-05-28T10:21:23.778416Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset all shape :  (5856, 200, 200)\n",
      "Dataset bp shape :  (3178, 200, 200)\n",
      "Dataset ration shape :  (4431, 200, 200)\n",
      "Dataset bp+ratio shape :  (2502, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "all_categories = []\n",
    "\n",
    "max_ratio_threshold = 1.6\n",
    "all_images_index_ratio = []\n",
    "\n",
    "min_black_pixels_threshold = 5\n",
    "all_images_indexes_black_pixels = []\n",
    "\n",
    "all_images_index_ratio_and_black_pixels = []\n",
    "\n",
    "datasetX = []\n",
    "datasetY = []\n",
    "\n",
    "image_size = (200, 200)\n",
    "\n",
    "def load_datasets(img, category):\n",
    "    new_img = cv2.resize(img, image_size)\n",
    "    all_images.append(new_img)\n",
    "    all_categories.append(category)\n",
    "\n",
    "    if img_is_in_ratio(img, max_ratio=max_ratio_threshold):\n",
    "        all_images_index_ratio.append(len(all_images)-1)\n",
    "\n",
    "    if img_has_atleast_black_pixels(img, threshold=min_black_pixels_threshold):\n",
    "        all_images_indexes_black_pixels.append(len(all_images)-1)\n",
    "\n",
    "    if img_has_atleast_black_pixels(img, threshold=min_black_pixels_threshold) and img_is_in_ratio(img, max_ratio=max_ratio_threshold):\n",
    "        all_images_index_ratio_and_black_pixels.append(len(all_images)-1)\n",
    "\n",
    "    \n",
    "browse_imgs(load_datasets)\n",
    "\n",
    "def use_all_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array(all_images)\n",
    "    datasetY = np.array(all_categories)\n",
    " \n",
    "def use_ratio_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_images_index_ratio])\n",
    "    datasetY = np.array([all_categories[i] for i in all_images_index_ratio])\n",
    "\n",
    "def use_black_pixel_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_images_indexes_black_pixels])\n",
    "    datasetY = np.array([all_categories[i] for i in all_images_indexes_black_pixels])\n",
    "\n",
    "def use_ratio_black_pixel_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_images_index_ratio_and_black_pixels])\n",
    "    datasetY = np.array([all_categories[i] for i in all_images_index_ratio_and_black_pixels])\n",
    "\n",
    "use_all_dataset()\n",
    "print(\"Dataset all shape : \", datasetX.shape)\n",
    "use_black_pixel_dataset()\n",
    "print(\"Dataset bp shape : \", datasetX.shape)\n",
    "use_ratio_dataset()\n",
    "print(\"Dataset ration shape : \", datasetX.shape)\n",
    "use_ratio_black_pixel_dataset()\n",
    "print(\"Dataset bp+ratio shape : \", datasetX.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN - Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras as vk\n",
    "import pandas as pd\n",
    "# from scikeras.wrappers import KerasRegressor\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution = mettre en évidence les caractéristiques de l'image.\n",
    "\n",
    "Poolling = réduire l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "core_size = 6\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(200, 200, 1)),\n",
    "    layers.Conv2D(64, core_size, activation='elu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(128, core_size, activation='elu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(256, core_size, activation='elu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(512, core_size, activation='elu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(num_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.losses.BinaryCrossentropy(from_logits=False),\n",
    "#               metrics=['recall', 'precision'])\n",
    "\n",
    "# 2ème méthode de compilation qui permet de configurer des paramètres supplémentaires lors de l'instanciation\n",
    "# si nécessaire\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain normalized\n",
      "(4684, 200, 200)\n",
      "(586, 200, 200)\n",
      "(586, 200, 200)\n",
      "Epoch 1/3\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 5s/step - loss: 12.2703 - precision: 0.8197 - recall: 0.8013 - val_loss: 2.2638 - val_precision: 0.7389 - val_recall: 1.0000\n",
      "Epoch 2/3\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m794s\u001b[0m 5s/step - loss: 0.3232 - precision: 0.9274 - recall: 0.9375 - val_loss: 4.1336 - val_precision: 0.7389 - val_recall: 1.0000\n",
      "Epoch 3/3\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m786s\u001b[0m 5s/step - loss: 0.5298 - precision: 0.9322 - recall: 0.9403 - val_loss: 2.4042 - val_precision: 0.7389 - val_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cb8b55b050>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_all_dataset()\n",
    "\n",
    "# Nouvelle méthode de split pour avoir plus de données d'entrainement\n",
    "# First, split the data into train (80%) and others (20%)\n",
    "trainx, otherX, trainy, otherY = train_test_split(datasetX, datasetY, test_size=0.2, random_state=1)\n",
    "# Then, split others into validation (50%) and test (50%)\n",
    "xval, testx, yval, testy = train_test_split(otherX, otherY, test_size=0.5, random_state=1)\n",
    "# Results in 80% train, 10% validation, 10% test\n",
    "\n",
    "trainx = trainx / 255\n",
    "print(\"xtrain normalized\")\n",
    "testx = testx / 255\n",
    "xval = xval / 255\n",
    "\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(xval.shape)\n",
    "\n",
    "# For datasetY replace normal with 0 and pneumonia with 1 in order to have numeric values\n",
    "trainy = np.array([0 if y == \"NORMAL\" else 1 for y in trainy])\n",
    "testy = np.array([0 if y == \"NORMAL\" else 1 for y in testy])\n",
    "yval = np.array([0 if y == \"NORMAL\" else 1 for y in yval])\n",
    "\n",
    "model.fit(trainx,\n",
    "    trainy,\n",
    "    validation_data=(xval, yval),\n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 2.4268 - precision: 0.7585 - recall: 1.0000\n",
      "[2.6048924922943115, 1.0, 0.7491467595100403]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(testx, testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 147]\n",
      " [  0 439]]\n",
      "recall :  1.0\n",
      "precision :  0.7491467576791809\n",
      "f1score :  0.8565853658536585\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(testx)\n",
    "\n",
    "y_pred_label = np.round(y_pred).astype(int)\n",
    "\n",
    "cm = confusion_matrix(testy, y_pred_label)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.show()\n",
    "\n",
    "print(cm)\n",
    "recall = recall_score(testy, y_pred_label)\n",
    "precision = precision_score(testy, y_pred_label)\n",
    "f1score = f1_score(testy, y_pred_label)\n",
    "print(\"recall : \", recall)\n",
    "print(\"precision : \", precision)\n",
    "print(\"f1score : \", f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tentative GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain normalized\n",
      "(4684, 200, 200)\n",
      "(586, 200, 200)\n",
      "(586, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "use_all_dataset()\n",
    "\n",
    "trainx, otherX, trainy, otherY = train_test_split(datasetX, datasetY, test_size=0.2, random_state=1)\n",
    "xval, testx, yval, testy = train_test_split(otherX, otherY, test_size=0.5, random_state=1)\n",
    "\n",
    "trainx = trainx / 255\n",
    "print(\"xtrain normalized\")\n",
    "testx = testx / 255\n",
    "xval = xval / 255\n",
    "\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(xval.shape)\n",
    "\n",
    "# For datasetY replace normal with 0 and pneumonia with 1 in order to have numeric values\n",
    "trainy = np.array([0 if y == \"NORMAL\" else 1 for y in trainy])\n",
    "testy = np.array([0 if y == \"NORMAL\" else 1 for y in testy])\n",
    "yval = np.array([0 if y == \"NORMAL\" else 1 for y in yval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes= 1\n",
    "core_size = 4\n",
    "\n",
    "def create_model(optimizer='adam'):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(200, 200, 1)),\n",
    "        layers.Conv2D(64, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(16, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model crée\n",
      "param grid défini\n",
      "fit va commencer\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 953. MiB for an array with shape (3123, 200, 200) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 880, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 158, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 267, in _safe_indexing\n    return _array_indexing(X, indices, indices_dtype, axis=axis)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 33, in _array_indexing\n    return array[key, ...] if axis == 0 else array[:, key]\n           ~~~~~^^^^^^^^^^\n  File \"c:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 335, in __getitem__\n    res = super().__getitem__(index)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 953. MiB for an array with shape (3123, 200, 200) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit va commencer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# summarize results\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:914\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    910\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    911\u001b[0m         )\n\u001b[0;32m    912\u001b[0m     )\n\u001b[1;32m--> 914\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Timothée\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 953. MiB for an array with shape (3123, 200, 200) and data type float64"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=3)\n",
    "\n",
    "print(\"model crée\")\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "\n",
    "print(\"param grid défini\")\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "print(\"fit va commencer\")\n",
    "grid_result = grid.fit(trainx, trainy)\n",
    "print(\"fit done\")\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation curve core_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain normalized\n",
      "(4684, 200, 200)\n",
      "(1172, 200, 200)\n",
      "(937, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "use_all_dataset()\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(datasetX, datasetY, test_size=0.2, random_state=1)\n",
    "xtrain, xval, ytrain, yval = train_test_split(trainx, trainy, test_size=0.2, random_state=1)\n",
    "\n",
    "xtrain = xtrain / 255\n",
    "print(\"xtrain normalized\")\n",
    "testx = testx / 255\n",
    "xval = xval / 255\n",
    "\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(xval.shape)\n",
    "\n",
    "# For datasetY replace normal with 0 and pneumonia with 1 in order to have numeric values\n",
    "ytrain = np.array([0 if y == \"NORMAL\" else 1 for y in ytrain])\n",
    "testy = np.array([0 if y == \"NORMAL\" else 1 for y in testy])\n",
    "yval = np.array([0 if y == \"NORMAL\" else 1 for y in yval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def create_model done\n",
      "model defined\n",
      "start validation_curve\n",
      "Epoch 1/2\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 215ms/step - loss: 0.5293 - recall: 0.9675\n",
      "Epoch 2/2\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 219ms/step - loss: 0.2089 - recall: 0.9439\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step\n",
      "Epoch 1/2\n",
      "\u001b[1m33/79\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 968ms/step - loss: 0.6887 - recall: 1.0000"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Define a function to create a model with a given core_size\n",
    "def create_model(core_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(200, 200, 1)),\n",
    "        layers.Conv2D(64, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(62, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(16, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['recall'])\n",
    "    return model\n",
    "\n",
    "print(\"def create_model done\")\n",
    "\n",
    "# Wrap the model in a KerasClassifier\n",
    "model = KerasClassifier(model=create_model, verbose=1, core_size=2, epochs=2)\n",
    "\n",
    "print(\"model defined\")\n",
    "\n",
    "# Define the range of core_sizes to evaluate\n",
    "core_sizes = [2, 6, 8]\n",
    "\n",
    "print(\"start validation_curve\")\n",
    "# Compute the validation curve\n",
    "train_scores, valid_scores = validation_curve(\n",
    "    model, xtrain, ytrain, param_name=\"core_size\", param_range=core_sizes, cv=3, scoring=\"recall\"\n",
    ")\n",
    "print(\"end validation_curve\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(core_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "plt.plot(core_sizes, np.mean(valid_scores, axis=1), label='Cross-validation score')\n",
    "plt.title('Validation curve for core_size')\n",
    "plt.xlabel('core_size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation curve epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Liste pour stocker les scores de validation\n",
    "val_scores = []\n",
    "core_size = 8\n",
    "\n",
    "# Liste des nombres d'epochs à tester\n",
    "epochs_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    # Créer un nouveau modèle pour chaque itération\n",
    "    model = create_model(core_size)\n",
    "\n",
    "    # Entraîner le modèle avec le nombre actuel d'epochs\n",
    "    history = model.fit(xtrain, ytrain, validation_data=(xval, yval), epochs=epochs, verbose=1)\n",
    "\n",
    "    # Obtenir le score de validation du dernier epoch et l'ajouter à la liste\n",
    "    val_scores.append(history.history['val_loss'][-1])\n",
    "\n",
    "# Tracer les scores de validation en fonction du nombre d'epochs\n",
    "plt.plot(epochs_list, val_scores)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss vs. Number of Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(xtrain,\n",
    "                    ytrain,\n",
    "                    validation_data=(xval, yval),\n",
    "                    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation precision\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history.history['precision'], label='Training Precision')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation recall\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history.history['recall'], label='Training Recall')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
