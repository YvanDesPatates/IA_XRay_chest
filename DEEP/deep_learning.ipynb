{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:06:30.598166Z",
     "start_time": "2024-06-11T13:06:30.446444Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions utilitaires pour parcourir les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:06:30.603973Z",
     "start_time": "2024-06-11T13:06:30.599263Z"
    }
   },
   "outputs": [],
   "source": [
    "common_path = \"../chest_Xray/\"\n",
    "images_files = os.listdir(common_path)\n",
    "subfolders = [\"train\",\"val\",\"test\"]\n",
    "categories = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "\n",
    "# Permet de parcourir les images, et pour chaque image, on applique une fonction de callback\n",
    "# On peut optionnellement appeler une fonction de callback pour chaque dossier\n",
    "def browse_imgs(img_callback, path_folder_callback = None, limit_size = None):\n",
    "    for subfolder in subfolders:\n",
    "        for category in categories:\n",
    "            # pour avoir tous les chemins des 6 dossiers\n",
    "            folder_path = os.path.join(common_path, subfolder, category)\n",
    "            # liste de toutes les images\n",
    "            images_files = os.listdir(folder_path)\n",
    "            if path_folder_callback is not None:\n",
    "                path_folder_callback(folder_path, images_files)\n",
    "            array_limit = limit_size if limit_size is not None else len(images_files)\n",
    "            #récupération de toutes les (ou des 'limit_size' premières) images du dossier.\n",
    "            for file_name in images_files[:array_limit]:\n",
    "                if not file_name.endswith(\".jpeg\"):\n",
    "                    continue\n",
    "                image_path = os.path.join(folder_path,file_name)\n",
    "                img = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "                img_callback(img, category)\n",
    "                \n",
    "                \n",
    "def display_imgs(imgs, titles = [], plot_size = (1,1), figsize = (10,8)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    index = 0\n",
    "    for image, title in zip(imgs, titles):\n",
    "        index += 1\n",
    "        ax = fig.add_subplot(plot_size[0], plot_size[1], index) \n",
    "        ax.imshow(image, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        if titles is not None:\n",
    "            ax.set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T13:06:30.606788Z",
     "start_time": "2024-06-11T13:06:30.604641Z"
    }
   },
   "outputs": [],
   "source": [
    "def img_is_in_ratio(img, min_ratio = 1, max_ratio = 1.5):\n",
    "    height, width = img.shape\n",
    "    ratio = width / height\n",
    "    if min_ratio <= ratio <= max_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T13:06:30.609682Z",
     "start_time": "2024-06-11T13:06:30.607811Z"
    }
   },
   "outputs": [],
   "source": [
    "grey_scale_limit = 10\n",
    "\n",
    "def img_has_atleast_black_pixels(img, threshold = 5):\n",
    "    height, width = img.shape\n",
    "    percent = (np.sum(img <= grey_scale_limit)*100)/(width*height)\n",
    "    return percent >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T13:07:04.668518Z",
     "start_time": "2024-06-11T13:06:30.610262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset all shape :  (5856, 200, 200)\n",
      "Dataset bp shape :  (3178, 200, 200)\n",
      "Dataset ration shape :  (4431, 200, 200)\n",
      "Dataset bp+ratio shape :  (2502, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "all_categories = []\n",
    "\n",
    "all_original_images_index = []\n",
    "\n",
    "max_ratio_threshold = 1.6\n",
    "all_images_index_ratio = []\n",
    "\n",
    "min_black_pixels_threshold = 5\n",
    "all_images_indexes_black_pixels = []\n",
    "\n",
    "all_images_index_ratio_and_black_pixels = []\n",
    "\n",
    "datasetX = []\n",
    "datasetY = []\n",
    "\n",
    "image_size = (200, 200)\n",
    "\n",
    "def load_datasets(img, category):\n",
    "    new_img = cv2.resize(img, image_size)\n",
    "    all_images.append(new_img)\n",
    "    all_categories.append(category)\n",
    "    index = len(all_images)-1\n",
    "    all_images.append(new_img)\n",
    "    all_categories.append(category)\n",
    "    \n",
    "    all_original_images_index.append(index)\n",
    "\n",
    "    if img_is_in_ratio(img, max_ratio=max_ratio_threshold):\n",
    "        all_images_index_ratio.append(index)\n",
    "\n",
    "    if img_has_atleast_black_pixels(img, threshold=min_black_pixels_threshold):\n",
    "        all_images_indexes_black_pixels.append(index)\n",
    "\n",
    "    if img_has_atleast_black_pixels(img, threshold=min_black_pixels_threshold) and img_is_in_ratio(img, max_ratio=max_ratio_threshold):\n",
    "        all_images_index_ratio_and_black_pixels.append(index)\n",
    "\n",
    "    \n",
    "browse_imgs(load_datasets)\n",
    "\n",
    "def use_all_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array(all_images)\n",
    "    datasetY = np.array(all_categories)\n",
    "    \n",
    "def use_all_original_images_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_original_images_index])\n",
    "    datasetY = np.array([all_categories[i] for i in all_original_images_index])\n",
    " \n",
    "def use_ratio_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_images_index_ratio])\n",
    "    datasetY = np.array([all_categories[i] for i in all_images_index_ratio])\n",
    "\n",
    "def use_black_pixel_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_images_indexes_black_pixels])\n",
    "    datasetY = np.array([all_categories[i] for i in all_images_indexes_black_pixels])\n",
    "\n",
    "def use_ratio_black_pixel_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_images_index_ratio_and_black_pixels])\n",
    "    datasetY = np.array([all_categories[i] for i in all_images_index_ratio_and_black_pixels])\n",
    "\n",
    "use_all_dataset()\n",
    "print(\"Dataset all shape : \", datasetX.shape)\n",
    "use_black_pixel_dataset()\n",
    "print(\"Dataset bp shape : \", datasetX.shape)\n",
    "use_ratio_dataset()\n",
    "print(\"Dataset ration shape : \", datasetX.shape)\n",
    "use_ratio_black_pixel_dataset()\n",
    "print(\"Dataset bp+ratio shape : \", datasetX.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN - Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:07:40.266244Z",
     "start_time": "2024-06-11T13:07:40.250381Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualkeras'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layers\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mvisualkeras\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mvk\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'visualkeras'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import visualkeras as vk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution = mettre en évidence les caractéristiques de l'image.\n",
    "\n",
    "Poolling = réduire l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:07:45.393267Z",
     "start_time": "2024-06-11T13:07:45.307343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m197\u001B[0m, \u001B[38;5;34m197\u001B[0m, \u001B[38;5;34m256\u001B[0m)  │         \u001B[38;5;34m4,352\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001B[38;5;33mMaxPooling2D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m98\u001B[0m, \u001B[38;5;34m98\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m95\u001B[0m, \u001B[38;5;34m95\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │       \u001B[38;5;34m524,416\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m47\u001B[0m, \u001B[38;5;34m47\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m44\u001B[0m, \u001B[38;5;34m44\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │       \u001B[38;5;34m131,136\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m22\u001B[0m, \u001B[38;5;34m22\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30976\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │     \u001B[38;5;34m1,982,528\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m65\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,416</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30976</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,982,528</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2,642,497\u001B[0m (10.08 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,642,497</span> (10.08 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m2,642,497\u001B[0m (10.08 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,642,497</span> (10.08 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This line sets the number of output classes for your model\n",
    "num_classes = 1\n",
    "# This line sets the size of the kernel to be used in the convolutional layers. The kernel is\n",
    "# a small matrix that is used for blurring, sharpening, embossing, edge detection, and more\n",
    "core_size = 4\n",
    "\n",
    "# he Sequential model is a linear stack of layers that you can add to in order\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(200, 200, 1)),\n",
    "    layers.Conv2D(256, core_size, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, core_size, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, core_size, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:07:45.750337Z",
     "start_time": "2024-06-11T13:07:45.736782Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-06-11T13:07:46.088093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainx normalized\n",
      "testx normalized\n",
      "[[[0.08627451 0.08235294 0.08627451 ... 0.0745098  0.02352941 0.54117647]\n",
      "  [0.08235294 0.08235294 0.08627451 ... 0.4627451  0.56078431 0.58823529]\n",
      "  [0.07843137 0.08235294 0.08627451 ... 0.45490196 0.47843137 0.58431373]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.12156863 0.12156863 0.11764706 ... 0.12156863 0.11764706 0.11764706]\n",
      "  [0.11372549 0.11372549 0.09803922 ... 0.12156863 0.11764706 0.11764706]\n",
      "  [0.10588235 0.09411765 0.10588235 ... 0.1254902  0.12156863 0.11764706]\n",
      "  ...\n",
      "  [0.12941176 0.09803922 0.19607843 ... 0.17647059 0.17647059 0.17647059]\n",
      "  [0.11764706 0.12156863 0.19607843 ... 0.17647059 0.17647059 0.17647059]\n",
      "  [0.11372549 0.16078431 0.20784314 ... 0.17647059 0.17647059 0.17647059]]\n",
      "\n",
      " [[0.04313725 0.04313725 0.03529412 ... 0.08627451 0.08235294 0.0745098 ]\n",
      "  [0.04313725 0.04313725 0.03137255 ... 0.09019608 0.07843137 0.0745098 ]\n",
      "  [0.04313725 0.04313725 0.02745098 ... 0.08627451 0.08627451 0.07843137]\n",
      "  ...\n",
      "  [0.07843137 0.0745098  0.0745098  ... 0.05098039 0.05098039 0.05098039]\n",
      "  [0.0745098  0.0745098  0.07058824 ... 0.05098039 0.05098039 0.05098039]\n",
      "  [0.0745098  0.0745098  0.07058824 ... 0.05098039 0.05098039 0.05098039]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.05882353 0.05490196 0.05490196 ... 0.78039216 0.76078431 0.76862745]\n",
      "  [0.05098039 0.04705882 0.04705882 ... 0.79215686 0.78431373 0.76470588]\n",
      "  [0.04705882 0.04313725 0.04313725 ... 0.79607843 0.76470588 0.75294118]\n",
      "  ...\n",
      "  [0.1254902  0.1254902  0.1254902  ... 0.11372549 0.13333333 0.17647059]\n",
      "  [0.08627451 0.13333333 0.1254902  ... 0.11372549 0.1372549  0.0627451 ]\n",
      "  [0.11372549 0.11764706 0.1254902  ... 0.10980392 0.11764706 0.16470588]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.2627451  0.24705882 0.24313725]\n",
      "  [0.         0.         0.         ... 0.25882353 0.24705882 0.23921569]\n",
      "  [0.         0.         0.         ... 0.24313725 0.23921569 0.24705882]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.5254902  0.57254902 0.63529412 ... 0.31764706 0.34117647 0.31764706]\n",
      "  [0.54117647 0.58823529 0.55294118 ... 0.3254902  0.3372549  0.31372549]\n",
      "  [0.55294118 0.63137255 0.50196078 ... 0.30980392 0.34509804 0.30588235]\n",
      "  ...\n",
      "  [0.12941176 0.22745098 0.24705882 ... 0.11372549 0.07058824 0.03921569]\n",
      "  [0.1372549  0.20392157 0.30980392 ... 0.11764706 0.06666667 0.04705882]\n",
      "  [0.13333333 0.21960784 0.28235294 ... 0.1254902  0.07843137 0.04705882]]]\n",
      "(4684, 200, 200)\n",
      "[1 1 1 ... 1 0 1]\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py:669: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m100/147\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:49\u001B[0m 2s/step - loss: 0.5841 - recall: 0.9468"
     ]
    }
   ],
   "source": [
    "use_all_dataset()\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(datasetX, datasetY, test_size=0.2, random_state=1)\n",
    "trainx = trainx / 255\n",
    "print(\"trainx normalized\")\n",
    "testx = testx / 255\n",
    "print(\"testx normalized\")\n",
    "\n",
    "# For datasetY replace normal with 0 and pneumonia with 1 in order to have numeric values\n",
    "trainy = np.array([0 if y == \"NORMAL\" else 1 for y in trainy])\n",
    "testy = np.array([0 if y == \"NORMAL\" else 1 for y in testy])\n",
    "\n",
    "# déterminer le type de cette variable\n",
    "print(trainx)\n",
    "print(trainx.shape)\n",
    "print(trainy)\n",
    "# print(trainy.shape)\n",
    "\n",
    "model.fit(trainx,\n",
    "          trainy,\n",
    "          validation_data=(testx, testy),\n",
    "          epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(model.evaluate(testx, testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Predict the probabilities\n",
    "y_pred = model.predict(testx)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred_label = np.round(y_pred).astype(int)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(testy, y_pred_label)\n",
    "\n",
    "print(cm)\n",
    "recall = recall_score(testy, y_pred_label)\n",
    "precision = precision_score(testy, y_pred_label)\n",
    "f1score = f1_score(testy, y_pred_label)\n",
    "print(\"recall : \", recall)\n",
    "print(\"precision : \", precision)\n",
    "print(\"f1score : \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
