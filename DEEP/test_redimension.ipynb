{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests sur les dimensions d'images\n",
    "\n",
    "Le but de ce test est de déterminer la dimension idéale des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T19:21:24.835365Z",
     "start_time": "2024-07-02T19:21:22.189926Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.10 (you have 1.4.8). Upgrade using: pip install --upgrade albumentations\n",
      "2024-07-02 21:21:23.210767: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-02 21:21:23.211934: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 21:21:23.254742: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 21:21:23.391522: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 21:21:24.195762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import albumentations as alb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size :  (100, 100)\n",
      "Epoch 1/2\n",
      "\u001B[1m147/147\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 40ms/step - loss: 0.5758 - precision: 0.7426 - recall: 0.9912 - val_loss: 0.3489 - val_precision: 0.8330 - val_recall: 0.9529\n",
      "Epoch 2/2\n",
      "\u001B[1m147/147\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - loss: 0.2865 - precision: 0.9124 - recall: 0.9218 - val_loss: 0.2311 - val_precision: 0.9490 - val_recall: 0.9231\n",
      "time of execution for  (100, 100)  size :  13.555516004562378\n",
      "img_size :  (200, 200)\n",
      "Epoch 1/2\n",
      "\u001B[1m147/147\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 205ms/step - loss: 0.5655 - precision: 0.7544 - recall: 0.9793 - val_loss: 0.2853 - val_precision: 0.8600 - val_recall: 0.9840\n",
      "Epoch 2/2\n",
      "\u001B[1m147/147\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 202ms/step - loss: 0.2128 - precision: 0.9422 - recall: 0.9442 - val_loss: 0.1776 - val_precision: 0.9292 - val_recall: 0.9908\n",
      "time of execution for  (200, 200)  size :  63.54679322242737\n",
      "img_size :  (400, 400)\n"
     ]
    }
   ],
   "source": [
    "max_image_size = (600, 600)\n",
    "x_total = []\n",
    "y_total = []\n",
    "\n",
    "def load_datasets(img, category):\n",
    "    new_img = cv2.resize(img, max_image_size)\n",
    "    x_total.append(new_img)\n",
    "    category = 0 if category == \"NORMAL\" else 1\n",
    "    y_total.append(category)\n",
    "\n",
    "\n",
    "tools.browse_imgs(load_datasets)\n",
    "\n",
    "steps = [(100, 100), (200, 200), (400, 400), max_image_size]\n",
    "results = {}\n",
    "for image_size in steps:\n",
    "    print(\"img_size : \", image_size)\n",
    "    \n",
    "    num_classes = 1\n",
    "    core_size = 8\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(*image_size, 1)),\n",
    "        layers.Conv2D(16, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(300, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    metrics = ['recall', 'precision']\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = y_total\n",
    "    \n",
    "    for img in x_total:\n",
    "        new_img = cv2.resize(img, image_size)\n",
    "        x_train.append(new_img)        \n",
    "        \n",
    "    x_train = np.array(x_train) / 255\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
    "    x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(x_train,\n",
    "              y_train,\n",
    "              validation_data=(x_val, y_val),\n",
    "              epochs=2,\n",
    "              verbose=1)\n",
    "    \n",
    "    y_pred = model.predict(x_test, verbose=0)\n",
    "    y_pred_label = np.round(y_pred).astype(int)\n",
    "    results[image_size] = recall_score(y_test, y_pred_label)\n",
    "    print(\"time of execution for \",image_size,\" size : \", time.time() - start_time)\n",
    "    \n",
    "    \n",
    "plt.plot(results.keys(), results.values(), marker='.', label='Test Recall')\n",
    "plt.xlabel('Image Size')\n",
    "plt.ylabel('Model recall')\n",
    "plt.title('validation Curve on image size')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-02T19:56:49.538968Z"
    }
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
