{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:11:41.845766Z",
     "start_time": "2024-07-02T10:11:39.911403Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 12:11:40.290629: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-02 12:11:40.292526: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 12:11:40.330246: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 12:11:40.452253: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 12:11:41.295297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# calcul matriciel\n",
    "import numpy as np\n",
    "# utilisation des modèles\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MNISTLoader:\n",
    "  def __init__(self):\n",
    "    self.x_train = None\n",
    "    self.x_test = None\n",
    "    self.x_val = None\n",
    "    \n",
    "    self.x_test_normalized = None\n",
    "    self.x_train_normalized_80 = None\n",
    "    self.x_val_normalized_20 = None\n",
    "    self.y_test = None\n",
    "    self.y_train_80 = None\n",
    "    self.y_val_20 = None\n",
    "\n",
    "\n",
    "  def load_data(self):\n",
    "    (x_train, y_train), (self.x_test, self.y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train_normalized = x_train / 255\n",
    "    self.x_test_normalized = self.x_test / 255\n",
    "\n",
    "    self.x_train, self.x_val, self.y_train_80, self.y_val_20 = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "    self.x_train_normalized_80, self.x_val_normalized_20, self.y_train_80, self.y_val_20 = train_test_split(x_train_normalized, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "loader = MNISTLoader()\n",
    "loader.load_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:11:42.264633Z",
     "start_time": "2024-07-02T10:11:41.846736Z"
    }
   },
   "id": "c14c430918396762",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional model with handly data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "953238b9ed80a7fc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 11ms/step - accuracy: 0.9035 - loss: 0.3126 - val_accuracy: 0.9856 - val_loss: 0.0486\n",
      "Epoch 2/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 9ms/step - accuracy: 0.9864 - loss: 0.0449 - val_accuracy: 0.9833 - val_loss: 0.0501\n",
      "Epoch 3/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 9ms/step - accuracy: 0.9898 - loss: 0.0317 - val_accuracy: 0.9889 - val_loss: 0.0385\n",
      "Epoch 4/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 10ms/step - accuracy: 0.9937 - loss: 0.0199 - val_accuracy: 0.9889 - val_loss: 0.0393\n",
      "Epoch 5/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 10ms/step - accuracy: 0.9938 - loss: 0.0175 - val_accuracy: 0.9912 - val_loss: 0.0326\n",
      "Epoch 6/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 10ms/step - accuracy: 0.9959 - loss: 0.0136 - val_accuracy: 0.9902 - val_loss: 0.0379\n",
      "Epoch 7/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 10ms/step - accuracy: 0.9970 - loss: 0.0099 - val_accuracy: 0.9877 - val_loss: 0.0446\n",
      "Epoch 8/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 10ms/step - accuracy: 0.9972 - loss: 0.0084 - val_accuracy: 0.9898 - val_loss: 0.0460\n",
      "Epoch 9/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 10ms/step - accuracy: 0.9971 - loss: 0.0086 - val_accuracy: 0.9895 - val_loss: 0.0500\n",
      "Epoch 10/10\n",
      "\u001B[1m1500/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 10ms/step - accuracy: 0.9984 - loss: 0.0052 - val_accuracy: 0.9883 - val_loss: 0.0652\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9882 - loss: 0.0434\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.03459934517741203, 0.9911999702453613]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "core_size = 4\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(128, core_size, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, core_size, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(loader.x_train_normalized_80,\n",
    "          loader.y_train_80,\n",
    "          validation_data=(loader.x_val_normalized_20, loader.y_val_20),\n",
    "          epochs=10)\n",
    "\n",
    "model.evaluate(loader.x_test_normalized, loader.y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:18:18.703518Z",
     "start_time": "2024-07-02T10:15:48.141460Z"
    }
   },
   "id": "b2075246526be637",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Création de la fenêtre principale\n",
    "window = tk.Tk()\n",
    "\n",
    "canvas = tk.Canvas(window, width=280, height=280, bg='white')\n",
    "canvas.pack()\n",
    "\n",
    "image = Image.new('L', (280, 280), 255)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "def clear_canvas():\n",
    "    canvas.delete('all')\n",
    "    global image, draw\n",
    "    image = Image.new('L', (280, 280), 255)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "clear_button = tk.Button(window, text='Clear', command=clear_canvas)\n",
    "clear_button.pack()\n",
    "\n",
    "\n",
    "# Fonction appelée lors du dessin\n",
    "def draw_on_canvas(event):\n",
    "    x, y = event.x, event.y\n",
    "    canvas.create_oval(x, y, x+10, y+10, fill='black')\n",
    "    draw.rectangle([x, y, x+10, y+10], fill='black')\n",
    "\n",
    "# Fonction appelée lors de la prédiction\n",
    "def predict_digit():\n",
    "    # Redimensionner l'image à la taille attendue par le modèle (28x28)\n",
    "    resized_image = image.resize((28, 28))\n",
    "\n",
    "    # Prétraitement de l'image pour l'adapter au modèle (conversion en tableau numpy, normalisation, etc.)\n",
    "    preprocessed_image = preprocess_image(resized_image)\n",
    "\n",
    "    # Effectuer la prédiction avec le modèle\n",
    "    predictions = model.predict(np.expand_dims([preprocessed_image], axis=-1))[0]\n",
    "    prediction = np.argmax(predictions)\n",
    "\n",
    "    # Afficher la prédiction\n",
    "    prediction_label.config(text='Prediction: ' + str(prediction))\n",
    "\n",
    "# Fonction pour prétraiter l'image avant la prédiction\n",
    "def preprocess_image(image):\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image = image.convert('L')\n",
    "\n",
    "    # Convertir l'image en tableau numpy\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Inverser le noir et le blanc\n",
    "    image_array = 255 - image_array\n",
    "\n",
    "    # Trouver les limites du dessin (les coordonnées où il y a du noir)\n",
    "    nonzero_indices = np.nonzero(image_array)\n",
    "    min_x = np.min(nonzero_indices[1])\n",
    "    max_x = np.max(nonzero_indices[1])\n",
    "    min_y = np.min(nonzero_indices[0])\n",
    "    max_y = np.max(nonzero_indices[0])\n",
    "\n",
    "    # Extraire la zone contenant le dessin et la centrer dans une image 28x28\n",
    "    cropped_image = image_array[min_y:max_y, min_x:max_x]\n",
    "\n",
    "    # Redimensionner l'image à 28x28\n",
    "    resized_image = Image.fromarray(cropped_image).resize((28, 28))\n",
    "\n",
    "    # Normaliser l'image comme dans votre chargement de données\n",
    "    preprocessed_image = np.array(resized_image) / 255.0\n",
    "\n",
    "    # Ajouter une dimension pour correspondre à la forme attendue par le modèle\n",
    "    preprocessed_image = np.expand_dims(preprocessed_image, axis=-1)\n",
    "\n",
    "    return preprocessed_image\n",
    "\n",
    "predict_button = tk.Button(window, text='Predict', command=predict_digit)\n",
    "predict_button.pack()\n",
    "\n",
    "prediction_label = tk.Label(window, text='Prediction: ')\n",
    "prediction_label.pack()\n",
    "\n",
    "# Capturer les événements de dessin sur la toile\n",
    "canvas.bind('<B1-Motion>', draw_on_canvas)\n",
    "\n",
    "# Lancer l'application\n",
    "window.mainloop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:20:14.148451Z",
     "start_time": "2024-07-02T10:19:38.299224Z"
    }
   },
   "id": "cb473ab9615f71f3",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
