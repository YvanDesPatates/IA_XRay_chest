{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:21:23.122791Z",
     "start_time": "2024-05-28T10:21:22.808327Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions utilitaires pour parcourir les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:21:23.129519Z",
     "start_time": "2024-05-28T10:21:23.123955Z"
    }
   },
   "outputs": [],
   "source": [
    "common_path = \"./chest_Xray\"\n",
    "images_files = os.listdir(common_path)\n",
    "subfolders = [\"train\",\"val\",\"test\"]\n",
    "categories = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "\n",
    "# Permet de parcourir les images, et pour chaque image, on applique une fonction de callback\n",
    "# On peut optionnellement appeler une fonction de callback pour chaque dossier\n",
    "def browse_imgs(img_callback, path_folder_callback = None, limit_size = None):\n",
    "    for subfolder in subfolders:\n",
    "        for category in categories:\n",
    "            # pour avoir tous les chemins des 6 dossiers\n",
    "            folder_path = os.path.join(common_path, subfolder, category)\n",
    "            # liste de toutes les images\n",
    "            images_files = os.listdir(folder_path)\n",
    "            if path_folder_callback is not None:\n",
    "                path_folder_callback(folder_path, images_files)\n",
    "            array_limit = limit_size if limit_size is not None else len(images_files)\n",
    "            #récupération de toutes les (ou des 'limit_size' premières) images du dossier.\n",
    "            for file_name in images_files[:array_limit]:\n",
    "                if not file_name.endswith(\".jpeg\"):\n",
    "                    continue\n",
    "                image_path = os.path.join(folder_path,file_name)\n",
    "                img = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "                img_callback(img, category)\n",
    "                \n",
    "                \n",
    "def display_imgs(imgs, titles = [], plot_size = (1,1), figsize = (10,8)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    index = 0\n",
    "    for image, title in zip(imgs, titles):\n",
    "        index += 1\n",
    "        ax = fig.add_subplot(plot_size[0], plot_size[1], index) \n",
    "        ax.imshow(image, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        if titles is not None:\n",
    "            ax.set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:21:23.132639Z",
     "start_time": "2024-05-28T10:21:23.130402Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def img_is_in_ratio(img, min_ratio = 1, max_ratio = 1.5):\n",
    "    height, width = img.shape\n",
    "    ratio = width / height\n",
    "    if min_ratio <= ratio <= max_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:21:23.135806Z",
     "start_time": "2024-05-28T10:21:23.133528Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grey_scale_limit = 10\n",
    "\n",
    "def img_has_atleast_black_pixels(img, threshold = 5):\n",
    "    height, width = img.shape\n",
    "    percent = (np.sum(img <= grey_scale_limit)*100)/(width*height)\n",
    "    return percent >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:22:02.593104Z",
     "start_time": "2024-05-28T10:21:23.778416Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset all shape :  (5856, 200, 200)\n",
      "Dataset bp shape :  (3178, 200, 200)\n",
      "Dataset ration shape :  (4431, 200, 200)\n",
      "Dataset bp+ratio shape :  (2502, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "all_categories = []\n",
    "\n",
    "max_ratio_threshold = 1.6\n",
    "all_images_index_ratio = []\n",
    "\n",
    "min_black_pixels_threshold = 5\n",
    "all_images_indexes_black_pixels = []\n",
    "\n",
    "all_images_index_ratio_and_black_pixels = []\n",
    "\n",
    "datasetX = []\n",
    "datasetY = []\n",
    "\n",
    "image_size = (200, 200)\n",
    "\n",
    "def load_datasets(img, category):\n",
    "    new_img = cv2.resize(img, image_size)\n",
    "    all_images.append(new_img)\n",
    "    all_categories.append(category)\n",
    "\n",
    "    if img_is_in_ratio(img, max_ratio=max_ratio_threshold):\n",
    "        all_images_index_ratio.append(len(all_images)-1)\n",
    "\n",
    "    if img_has_atleast_black_pixels(img, threshold=min_black_pixels_threshold):\n",
    "        all_images_indexes_black_pixels.append(len(all_images)-1)\n",
    "\n",
    "    if img_has_atleast_black_pixels(img, threshold=min_black_pixels_threshold) and img_is_in_ratio(img, max_ratio=max_ratio_threshold):\n",
    "        all_images_index_ratio_and_black_pixels.append(len(all_images)-1)\n",
    "\n",
    "    \n",
    "browse_imgs(load_datasets)\n",
    "\n",
    "def use_all_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array(all_images)\n",
    "    datasetY = np.array(all_categories)\n",
    " \n",
    "def use_ratio_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_images_index_ratio])\n",
    "    datasetY = np.array([all_categories[i] for i in all_images_index_ratio])\n",
    "\n",
    "def use_black_pixel_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_images_indexes_black_pixels])\n",
    "    datasetY = np.array([all_categories[i] for i in all_images_indexes_black_pixels])\n",
    "\n",
    "def use_ratio_black_pixel_dataset():\n",
    "    global datasetX, datasetY\n",
    "    datasetX = np.array([all_images[i] for i in all_images_index_ratio_and_black_pixels])\n",
    "    datasetY = np.array([all_categories[i] for i in all_images_index_ratio_and_black_pixels])\n",
    "\n",
    "use_all_dataset()\n",
    "print(\"Dataset all shape : \", datasetX.shape)\n",
    "use_black_pixel_dataset()\n",
    "print(\"Dataset bp shape : \", datasetX.shape)\n",
    "use_ratio_dataset()\n",
    "print(\"Dataset ration shape : \", datasetX.shape)\n",
    "use_ratio_black_pixel_dataset()\n",
    "print(\"Dataset bp+ratio shape : \", datasetX.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN - Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras as vk\n",
    "import pandas as pd\n",
    "# from scikeras.wrappers import KerasRegressor\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution = mettre en évidence les caractéristiques de l'image.\n",
    "\n",
    "Poolling = réduire l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "core_size = 6\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(200, 200, 1)),\n",
    "    layers.Conv2D(64, core_size, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, core_size, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(16, core_size, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.losses.BinaryCrossentropy(from_logits=False),\n",
    "#               metrics=['recall', 'precision'])\n",
    "\n",
    "# 2ème méthode de compilation qui permet de configurer des paramètres supplémentaires lors de l'instanciation\n",
    "# si nécessaire\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain normalized\n",
      "(4684, 200, 200)\n",
      "(586, 200, 200)\n",
      "(586, 200, 200)\n",
      "Epoch 1/3\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 378ms/step - loss: 0.4724 - precision_2: 0.7586 - recall_38: 0.9826 - val_loss: 0.3012 - val_precision_2: 0.8952 - val_recall_38: 0.9861\n",
      "Epoch 2/3\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 453ms/step - loss: 0.3117 - precision_2: 0.9013 - recall_38: 0.9606 - val_loss: 0.2548 - val_precision_2: 0.9483 - val_recall_38: 0.9746\n",
      "Epoch 3/3\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 442ms/step - loss: 0.2948 - precision_2: 0.9128 - recall_38: 0.9631 - val_loss: 0.2718 - val_precision_2: 0.9118 - val_recall_38: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d1f5c7a900>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_all_dataset()\n",
    "\n",
    "# Nouvelle méthode de split pour avoir plus de données d'entrainement\n",
    "# First, split the data into train (80%) and others (20%)\n",
    "trainx, otherX, trainy, otherY = train_test_split(datasetX, datasetY, test_size=0.2, random_state=1)\n",
    "# Then, split others into validation (50%) and test (50%)\n",
    "xval, testx, yval, testy = train_test_split(otherX, otherY, test_size=0.5, random_state=1)\n",
    "# Results in 80% train, 10% validation, 10% test\n",
    "\n",
    "trainx = trainx / 255\n",
    "print(\"xtrain normalized\")\n",
    "testx = testx / 255\n",
    "xval = xval / 255\n",
    "\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(xval.shape)\n",
    "\n",
    "# For datasetY replace normal with 0 and pneumonia with 1 in order to have numeric values\n",
    "trainy = np.array([0 if y == \"NORMAL\" else 1 for y in trainy])\n",
    "testy = np.array([0 if y == \"NORMAL\" else 1 for y in testy])\n",
    "yval = np.array([0 if y == \"NORMAL\" else 1 for y in yval])\n",
    "\n",
    "model.fit(trainx,\n",
    "    trainy,\n",
    "    validation_data=(xval, yval),\n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - loss: 0.2755 - precision_2: 0.9116 - recall_38: 0.9789\n",
      "[0.28897425532341003, 0.981776773929596, 0.9054622054100037]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(testx, testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102  45]\n",
      " [  8 431]]\n",
      "recall :  0.9817767653758542\n",
      "precision :  0.9054621848739496\n",
      "f1score :  0.9420765027322404\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(testx)\n",
    "\n",
    "y_pred_label = np.round(y_pred).astype(int)\n",
    "\n",
    "cm = confusion_matrix(testy, y_pred_label)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.show()\n",
    "\n",
    "print(cm)\n",
    "recall = recall_score(testy, y_pred_label)\n",
    "precision = precision_score(testy, y_pred_label)\n",
    "f1score = f1_score(testy, y_pred_label)\n",
    "print(\"recall : \", recall)\n",
    "print(\"precision : \", precision)\n",
    "print(\"f1score : \", f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tentative GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain normalized\n"
     ]
    }
   ],
   "source": [
    "use_all_dataset()\n",
    "\n",
    "trainx, otherX, trainy, otherY = train_test_split(datasetX, datasetY, test_size=0.2, random_state=1)\n",
    "xval, testx, yval, testy = train_test_split(otherX, otherY, test_size=0.5, random_state=1)\n",
    "\n",
    "trainx = trainx / 255\n",
    "print(\"xtrain normalized\")\n",
    "testx = testx / 255\n",
    "xval = xval / 255\n",
    "\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(xval.shape)\n",
    "\n",
    "# For datasetY replace normal with 0 and pneumonia with 1 in order to have numeric values\n",
    "trainy = np.array([0 if y == \"NORMAL\" else 1 for y in trainy])\n",
    "testy = np.array([0 if y == \"NORMAL\" else 1 for y in testy])\n",
    "yval = np.array([0 if y == \"NORMAL\" else 1 for y in yval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes= 1\n",
    "core_size = 4\n",
    "\n",
    "def create_model(optimizer='adam'):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(200, 200, 1)),\n",
    "        layers.Conv2D(64, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(16, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model crée\n",
      "param grid défini\n",
      "fit va commencer\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit va commencer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# summarize results\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\fvenezia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=3)\n",
    "\n",
    "print(\"model crée\")\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "\n",
    "print(\"param grid défini\")\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "print(\"fit va commencer\")\n",
    "grid_result = grid.fit(trainx, trainy)\n",
    "print(\"fit done\")\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation curve core_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain normalized\n",
      "(4684, 200, 200)\n",
      "(1172, 200, 200)\n",
      "(937, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "use_all_dataset()\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(datasetX, datasetY, test_size=0.2, random_state=1)\n",
    "xtrain, xval, ytrain, yval = train_test_split(trainx, trainy, test_size=0.2, random_state=1)\n",
    "\n",
    "xtrain = xtrain / 255\n",
    "print(\"xtrain normalized\")\n",
    "testx = testx / 255\n",
    "xval = xval / 255\n",
    "\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(xval.shape)\n",
    "\n",
    "# For datasetY replace normal with 0 and pneumonia with 1 in order to have numeric values\n",
    "ytrain = np.array([0 if y == \"NORMAL\" else 1 for y in ytrain])\n",
    "testy = np.array([0 if y == \"NORMAL\" else 1 for y in testy])\n",
    "yval = np.array([0 if y == \"NORMAL\" else 1 for y in yval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def create_model done\n",
      "model defined\n",
      "start validation_curve\n",
      "Epoch 1/2\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 215ms/step - loss: 0.5293 - recall: 0.9675\n",
      "Epoch 2/2\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 219ms/step - loss: 0.2089 - recall: 0.9439\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step\n",
      "Epoch 1/2\n",
      "\u001b[1m33/79\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 968ms/step - loss: 0.6887 - recall: 1.0000"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Define a function to create a model with a given core_size\n",
    "def create_model(core_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(200, 200, 1)),\n",
    "        layers.Conv2D(64, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(62, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(16, core_size, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['recall'])\n",
    "    return model\n",
    "\n",
    "print(\"def create_model done\")\n",
    "\n",
    "# Wrap the model in a KerasClassifier\n",
    "model = KerasClassifier(model=create_model, verbose=1, core_size=2, epochs=2)\n",
    "\n",
    "print(\"model defined\")\n",
    "\n",
    "# Define the range of core_sizes to evaluate\n",
    "core_sizes = [2, 6, 8]\n",
    "\n",
    "print(\"start validation_curve\")\n",
    "# Compute the validation curve\n",
    "train_scores, valid_scores = validation_curve(\n",
    "    model, xtrain, ytrain, param_name=\"core_size\", param_range=core_sizes, cv=3, scoring=\"recall\"\n",
    ")\n",
    "print(\"end validation_curve\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(core_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "plt.plot(core_sizes, np.mean(valid_scores, axis=1), label='Cross-validation score')\n",
    "plt.title('Validation curve for core_size')\n",
    "plt.xlabel('core_size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation curve epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Liste pour stocker les scores de validation\n",
    "val_scores = []\n",
    "core_size = 8\n",
    "\n",
    "# Liste des nombres d'epochs à tester\n",
    "epochs_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    # Créer un nouveau modèle pour chaque itération\n",
    "    model = create_model(core_size)\n",
    "\n",
    "    # Entraîner le modèle avec le nombre actuel d'epochs\n",
    "    history = model.fit(xtrain, ytrain, validation_data=(xval, yval), epochs=epochs, verbose=1)\n",
    "\n",
    "    # Obtenir le score de validation du dernier epoch et l'ajouter à la liste\n",
    "    val_scores.append(history.history['val_loss'][-1])\n",
    "\n",
    "# Tracer les scores de validation en fonction du nombre d'epochs\n",
    "plt.plot(epochs_list, val_scores)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss vs. Number of Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(xtrain,\n",
    "                    ytrain,\n",
    "                    validation_data=(xval, yval),\n",
    "                    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation precision\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history.history['precision'], label='Training Precision')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation recall\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history.history['recall'], label='Training Recall')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
